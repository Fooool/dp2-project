{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harnessing Weather Insights for Accurate Energy Load Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi==2024.12.14 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (3.4.1)\n",
      "Requirement already satisfied: datetime==5.5 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (5.5)\n",
      "Requirement already satisfied: findspark==2.0.1 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (2.0.1)\n",
      "Requirement already satisfied: idna==3.10 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (3.10)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (0.10.9.7)\n",
      "Requirement already satisfied: pyspark==3.5.4 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 19)) (3.5.4)\n",
      "Requirement already satisfied: pytz==2024.2 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 21)) (2024.2)\n",
      "Requirement already satisfied: requests==2.32.3 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 23)) (2.32.3)\n",
      "Requirement already satisfied: urllib3==2.3.0 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 25)) (2.3.0)\n",
      "Requirement already satisfied: zope-interface==7.2 in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from -r requirements.txt (line 27)) (7.2)\n",
      "Requirement already satisfied: setuptools in p:\\development\\vs\\dp2-project\\.venv\\lib\\site-packages (from zope-interface==7.2->-r requirements.txt (line 27)) (75.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows OS detected\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "# Import the findspark module and use it to initialize the PySpark environment \n",
    "import findspark\n",
    "\n",
    "# Initialize via the full spark path\n",
    "if platform.system() == 'Windows':\n",
    "    print(\"Windows OS detected\")\n",
    "    findspark.init(\"C:/Spark/spark-3.5.4-bin-hadoop3\") # For my local machine\n",
    "else:\n",
    "    findspark.init(\"/usr/local/spark/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SparkSession module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "# Main entry point for Spark functionality. A SparkContext represents the\n",
    "# connection to a Spark cluster, and can be used to create :class:`RDD` and\n",
    "# broadcast variables on that cluster.      \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/geosphere\\2024-01-01_2024-12-31 copy.csv\n",
      "./data/geosphere\\2024-01-01_2024-12-31.csv\n",
      "root\n",
      " |-- time: string (nullable = true)\n",
      " |-- station: integer (nullable = true)\n",
      " |-- rr: double (nullable = true)\n",
      " |-- tl_mittel: double (nullable = true)\n",
      " |-- bewm_mittel: double (nullable = true)\n",
      " |-- so_h: double (nullable = true)\n",
      " |-- vv_mittel: double (nullable = true)\n",
      " |-- substation: integer (nullable = true)\n",
      "\n",
      "+--------------------+-------+----+---------+-----------+----+---------+----------+\n",
      "|                time|station|  rr|tl_mittel|bewm_mittel|so_h|vv_mittel|substation|\n",
      "+--------------------+-------+----+---------+-----------+----+---------+----------+\n",
      "|2024-01-01T00:00+...|      1| 0.0|      2.2|       80.0| 2.7|      2.1|     10200|\n",
      "|2024-01-01T00:00+...|    105| 0.4|      5.8|       53.0| 4.0|      4.5|      5904|\n",
      "|2024-01-02T00:00+...|      1| 0.1|     -0.4|       73.0| 1.9|      0.6|     10200|\n",
      "|2024-01-02T00:00+...|    105| 7.5|      4.8|       97.0| 0.0|      2.1|      5904|\n",
      "|2024-01-03T00:00+...|      1| 1.0|      2.9|       63.0| 5.9|      0.6|     10200|\n",
      "|2024-01-03T00:00+...|    105|-1.0|      9.3|       37.0| 7.6|      5.9|      5904|\n",
      "|2024-01-04T00:00+...|      1| 0.4|      2.6|       73.0| 3.2|      2.6|     10200|\n",
      "|2024-01-04T00:00+...|    105| 0.0|      8.8|       27.0| 6.3|     10.2|      5904|\n",
      "|2024-01-05T00:00+...|      1| 0.0|      3.1|       60.0| 1.2|      0.6|     10200|\n",
      "|2024-01-05T00:00+...|    105| 4.5|      6.5|       77.0| 3.1|      2.1|      5904|\n",
      "|2024-01-06T00:00+...|      1|10.7|      1.2|      100.0| 0.0|      0.6|     10200|\n",
      "|2024-01-06T00:00+...|    105|15.9|      3.9|      100.0| 0.0|      2.6|      5904|\n",
      "|2024-01-07T00:00+...|      1| 0.1|      0.4|       90.0| 0.0|      0.6|     10200|\n",
      "|2024-01-07T00:00+...|    105| 2.7|      2.2|      100.0| 0.0|      4.5|      5904|\n",
      "|2024-01-08T00:00+...|      1| 0.0|     -2.5|       93.0| 0.0|      2.1|     10200|\n",
      "|2024-01-08T00:00+...|    105| 0.8|     -3.2|      100.0| 0.0|      5.9|      5904|\n",
      "|2024-01-09T00:00+...|      1|-1.0|     -5.3|       83.0| 0.0|      0.6|     10200|\n",
      "|2024-01-09T00:00+...|    105|-1.0|     -6.9|       10.0| 5.2|      2.1|      5904|\n",
      "|2024-01-10T00:00+...|      1|-1.0|     -3.3|       20.0| 6.9|      2.1|     10200|\n",
      "|2024-01-10T00:00+...|    105|-1.0|     -4.9|        0.0| 7.4|      2.6|      5904|\n",
      "+--------------------+-------+----+---------+-----------+----+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "1464\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "\n",
    "# Folder Structure\n",
    "# data\n",
    "# |-- geosphere\n",
    "# |   |-- YYYY-MM-DD_YYYY-MM-DD.csv\n",
    "# |   |-- YYYY-MM-DD_YYYY-MM-DD.csv\n",
    "# |\n",
    "# |-- transparency\n",
    "# |   |-- YYYY\n",
    "# |      |-- MM.csv\n",
    "# |      |-- MM.csv\n",
    "\n",
    "# Loop through the geosphere folder and read in the data\n",
    "\n",
    "weather = None\n",
    "\n",
    "for filename in os.listdir(\"./data/geosphere\"):\n",
    "    file_path = os.path.join(\"./data/geosphere\", filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        print(file_path)\n",
    "        \n",
    "        # Read in the data\n",
    "        weather = spark.read.csv(\"./data/geosphere/2024-01-01_2024-12-31.csv\", header=True, inferSchema=True)\n",
    "        \n",
    "        # Combine the data\n",
    "        weather = weather.union(weather)\n",
    "\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "weather.printSchema()\n",
    "\n",
    "print(weather.show())\n",
    "\n",
    "print(weather.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
